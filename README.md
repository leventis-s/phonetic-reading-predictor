Program predicts the relative probability that a user learned to read and write phonetically or non-phonetically. Phonetic reading describes a strategy in which a person relies on the phonetic features of each letter in order to identify or write a word. In the United States, we often associate this method with the idea of “sounding it out.”  Conversely, non-phonetic reading and writing relies on one’s ability to memorize the structure of each word, not incorporating phonetic properties to decipher its meaning. For instance, a child who phonetically learns to read the word “cat”, may break down the word into its phonetic components, beginning with the sound [k] (for “c”), continuing with the sound [æ] (for “a”), and ending with the sound [t] (for “t”). On the other hand, a child who reads non-phonetically may see the word “cat”, make out its structure as the combination of its distinctive parts – “c”, “a”, and “t” – and recall the word's pronunciation. 

I first needed a dataset. Specifically, I wanted a dataset where I could see sample spellings from those who learned to read phonetically and those who learned to read non-phonetically. Unfortunately, this presented a great gap in the research, as this area is largely understudied. Thus, I had to create my own dataset. This means that the data may not be reliable, diverse, or generalizable; however, the goal of the project is to create a framework in which we could make predictions. With better and more reliable data, this framework can become more accurate.

The created dataset consists of a set of 11 words. For each word, I convert its pronunciation to a string composed of the International Phonetic Alphabet (IPA) using Archiba’s eng-to-ipa package. I had students of non-phonetic spelling backgrounds and phonetic spelling backgrounds take a “spelling test” with these words. Again, for each attempted spelling, I converted the English string to IPA. 

With this data – the spelling of specific words by phonetic and non-phonetic readers, I was able to create – for each word – two normal distributions: one for phonetic readers and one for non-phonetic readers. To clarify, this resulted in a total of 22 distributions: a phonetic distribution and non-phonetic distribution for each of the 11 words. The distributions represented the similarity index (using Jaro Similarity) between the IPA of the given word and the IPA of the student’s guess.

For example, after being converted to IPA, an original word like “beep” and a guess of “beap” would have a similarity index of 1.0, as, in IPA, they are both realized as [bip]. However, a word like “mop” and a guess of “map” would have a similarity of less than 1.0, as they are realized differently – respectively, [mɑp] and [mæp]. It is important to note that, in comparing the IPA similarities, I was not concerned with the students’ ability to spell each word “correctly”; rather, I was concerned with how well their spelling matched the phonetic pronunciation.

These distributions were the backbone of the created model. To use the model, a user listens to an audio of each of the 11 words (that I used to create my dataset). After each audio, the user inputs their best guess as to the spelling. Like the sample data, each guess is converted to IPA and subsequently scored with a Jaro Similarity Index, such that, by the end, I have a set of similarity indices. Then, using the PMF of each word distribution, I simply calculated the comparative probability that these similarity indices were pulled from the phonetic readers distribution over the non-phonetic reader distribution. With this, I was able to compute how much more probable it was that the user had learned to read phonetically or non-phonetically. 

For further explanation, see: https://www.youtube.com/watch?v=WXLdCdeGRhw
